# Homemade Machine Learning (Aprendizaje automatico casero)

> UA UCRANIA [EST√Å SIENDO ATACADA](https://war.ukraine.ua/) POR EL EJERCITO RUSO. CIVILES ESTAN SIENDO ASESINADOS. AREAS RESIDENCIALES ESTAN SIENDO BOMBARDEADAS.
> Ayuda a Ucrania via [National Bank of Ukraine](https://bank.gov.ua/en/news/all/natsionalniy-bank-vidkriv-spetsrahunok-dlya-zboru-koshtiv-na-potrebi-armiyi)
> - Ayuda a Ucrania via [SaveLife](https://savelife.in.ua/en/donate-en/) fund
> - M√°s informaci√≥n en [war.ukraine.ua](https://war.ukraine.ua/) y [MFA of Ukraine](https://twitter.com/MFA_Ukraine)

<hr/>

[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/trekhleb/homemade-machine-learning/master?filepath=notebooks)

> _Tambi√©n te podr√≠a interesar ü§ñ [Interactive Machine Learning Experiments](https://github.com/trekhleb/machine-learning-experiments)_

_Para la versi√≥n en Octave/MatLab de este repositiorio, visita [machine-learning-octave](https://github.com/trekhleb/machine-learning-octave) project._

> Este repositorio contiene ejemplos de algoritmos populares en machine learning implementados en **Python** con los racionales matem√°ticos explicados. Cada algoritmo tiene un **Jupiter Notebook** interactive asociado que te permite jugar con la data, la configuraci√≥n de los algoritmos e inmediatamente ver los resultados, gr√°ficas y predicciones **directamente en tu explorador**. En la mayor√≠a de los casos las explicaciones est√°n basadas en [this great machine learning course](https://www.coursera.org/learn/machine-learning) por Andrew Ng.

El prop√≥sito de este repositorio _no_ es de implementar algoritmos de machine learning utilizando bibliotecas desarrolladas por 3<sup>eros</sup> que consisten en comandos de una linea. El prop√≥sito es practicar la implementaci√≥n de estos algoritmos desde zero y por consiguiente mejorar el entendimieno de la matematica detr√°s de cada algoritmo. Es por esto que todas las implementaciones son llamadas "caseras" y no est√°n hachas para ser utilizadas fuera de un contexto did√°ctico.

## Supervised Learning (Aprendizaje supervisado)

En este tipo de algoritmos contamos con un set de data de entrenamiento (training data) como entrada y un set de etiquetas o "respuestas correctas" correspondiente con ladata de entrada que serviran como salida. El prop√≥sito es entrenar nuestro modelo (parametros del algoritmo) para emparejar los datos de entrada con los de salida correctamente (hacer predicciones correctas). Esto con el fin de encontrar los parametros del modelo que continuaran este emparejamiento (correcto) de _entrada+salida_ con nuevos datos.

### Regression (Regresi√≥n)

En problemas de regresi√≥n hacemos predicciones de datos reales. B√°sicamente intentamos dibujar una linea/plano atrav√©s de los ejemplos de entrenamiento. 

_Ejemplos de uso: pronostico de precios de acciones, an√°lisis de ventas, dependencias numericas, etc..._

#### ü§ñ Linear Regression (Regresi√≥n linear)

- üìó [Math | Linear Regression](homemade/linear_regression) - teor√≠a y m√°s para leer (en ingl√©s)
- ‚öôÔ∏è [Code | Linear Regression](homemade/linear_regression/linear_regression.py) - ejemplo de implementaci√≥n
- ‚ñ∂Ô∏è [Demo | Univariate Linear Regression (Regresi√≥n univariable)](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/linear_regression/univariate_linear_regression_demo.ipynb) - predecir la evaluacion de `country happiness (felicidad en el pa√≠s)` usando `economy GDP (producto interno bruto)`
- ‚ñ∂Ô∏è [Demo | Multivariate Linear Regression(Regresi√≥n multivariable)](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/linear_regression/multivariate_linear_regression_demo.ipynb) - predecir la evaluacion de `country happiness (felicidad en el pa√≠s)` usando `economy GDP (producto interno bruto)` y `freedom index (√≠ndice de libertad)`
- ‚ñ∂Ô∏è [Demo | Non-linear Regression](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/linear_regression/non_linear_regression_demo.ipynb) - usar regresi√≥n linear con caracteristicas _polinimiales_ y _sinusoidales_ para predecir dependencias no-lineales

### Classification (Clasificaci√≥n)

En problemas de clasificaci√≥n no contamos con etiquetas o "respuestas correctas". En este tipo de problemas dividimos la data de entrada en grupos dependiendo sus caracter√≠sticas. 

_Ejemplos de uso: filtros de spam, detecci√≥n de lenguaje, encontrar documentos similares, reconocimiento de letras escritas a mano, etc..._

#### ü§ñ Logistic Regression (Regresi√≥n log√≠stica)

- üìó [Math | Logistic Regression](homemade/logistic_regression) - teor√≠a y m√°s para leer (en ingl√©s)
- ‚öôÔ∏è [Code | Logistic Regression](homemade/logistic_regression/logistic_regression.py) - ejemplo de implementaci√≥n
- ‚ñ∂Ô∏è [Demo | Logistic Regression (Linear Boundary)](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/logistic_regression/logistic_regression_with_linear_boundary_demo.ipynb) - predecir la `class (clase)` de flor basado en `petal_length (longitud del p√©talo)` y `petal_width (ancho del p√©talo)`
- ‚ñ∂Ô∏è [Demo | Logistic Regression (Non-Linear Boundary)](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/logistic_regression/logistic_regression_with_non_linear_boundary_demo.ipynb) - predicir la `validity (validez)` de un microchip basado en `param_1` y `param_2`
- ‚ñ∂Ô∏è [Demo | Multivariate Logistic Regression | MNIST](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/logistic_regression/multivariate_logistic_regression_demo.ipynb) - reconocer n√∫meros escritos a mano en imagenes de `28x28` pixeles 
- ‚ñ∂Ô∏è [Demo | Multivariate Logistic Regression | Fashion MNIST](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/logistic_regression/multivariate_logistic_regression_fashion_demo.ipynb) - reconocer art√≠culos de ropa en imagenes de `28x28` pixeles 

## Unsupervised Learning (Aprendizaje no supervisado)

Aprendizaje no supervisado es una rama del machine learning que aprende de data que no ha sido etiquetada, clasificada o categorizada. En lugar de aprender de retoralimentaci√≥n, unsupervised learning identifica caracteristicas en com√∫n de la data y reacciona de acuerdo a la presencia (o ausencia) de estas caracteristicas en data nueva.  

### Clustering (Cl√∫stering)

En problemas de cl√∫stering dividimos los ejemplos de entrenamiento por caracteristicas desconocidas. El algoritmo en si decide que caracteristicas usa para hacer esta divisi√≥n.

_Ejemplos de uso: segmentaci√≥n de mercados, analysis de redes sociales, organizar cl√∫sters de c√≥mputo, an√°lisis de data astron√≥mica, compresi√≥n de imagenes, etc..._

#### ü§ñ K-means Algorithm (Algoritmo K-means)

- üìó [Math | K-means Algorithm](homemade/k_means) - teor√≠a y m√°s para leer (en ingl√©s)
- ‚öôÔ∏è [Code | K-means Algorithm](homemade/k_means/k_means.py) - ejemplo de implementaci√≥n
- ‚ñ∂Ô∏è [Demo | K-means Algorithm](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/k_means/k_means_demo.ipynb) - dividir flores en cl√∫sters basandonos en `petal_length (longitud del p√©talo)` y `petal_width (ancho del p√©talo)`

### Anomaly Detection (Detecci√≥n de anomal√≠as)

La detecci√≥n de anomal√≠as es la identificaci√≥n de articulos, eventos o observaciones raras que levantan sospechas ya que difieren significativamente de la mayor√≠a de la data. 

_Ejemplos de uso: detecci√≥n de intrusos, detecci√≥n de fraude, monitoreo de la salud del sistema, remover data an√≥mala de un set, etc..._

#### ü§ñ Anomaly Detection using Gaussian Distribution (Detecci√≥n de anomal√≠as utilizando la Distribuci√≥n Normal)

- üìó [Math | Anomaly Detection using Gaussian Distribution](homemade/anomaly_detection) - teor√≠a y m√°s para leer (en ingl√©s)
- ‚öôÔ∏è [Code | Anomaly Detection using Gaussian Distribution](homemade/anomaly_detection/gaussian_anomaly_detection.py) - ejemplo de implementaci√≥n
- ‚ñ∂Ô∏è [Demo | Anomaly Detection](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/anomaly_detection/anomaly_detection_gaussian_demo.ipynb) - encontrar anomal√≠as en los parametros de servicio de un servidor como `latency` y `threshold`

## Neural Network (NN) (Redes Neurales)

Las NN en si no son un algoritmo, m√°s bien son un marke de referencia para el uso de varios algoritmos juntos y el procesamiento de data compleja. 

_Ejemplos de uso: como un substituto sobre todos los dem√°s algoritmos en general, reconocimiento de imagenes, procesamiento de imagened (aplicando cierts estilos), traducciones, etc..._

#### ü§ñ Multilayer Perceptron (MLP) (Perceptr√≥n de multiples capas)

- üìó [Math | Multilayer Perceptron](homemade/neural_network) - teor√≠a y m√°s para leer (en ingl√©s)
- ‚öôÔ∏è [Code | Multilayer Perceptron](homemade/neural_network/multilayer_perceptron.py) - ejemplo de implementaci√≥n
- ‚ñ∂Ô∏è [Demo | Multilayer Perceptron | MNIST](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/neural_network/multilayer_perceptron_demo.ipynb) - reconocer n√∫meros escritos a mano en imagenes de `28x28` pixeles
- ‚ñ∂Ô∏è [Demo | Multilayer Perceptron | Fashion MNIST](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/neural_network/multilayer_perceptron_fashion_demo.ipynb) - reconocer art√≠culos de ropa en imagenes de `28x28` pixeles 

## Mapa de Machine Learning (ingl√©s)

![Machine Learning Map](images/machine-learning-map.png)

La fuente de este mapa es [este maravilloso blog post](https://vas3k.ru/blog/machine_learning/)

## Prerequisitos

#### Instalaci√≥n de Python

Asegura de tener [Python instalado](https://realpython.com/installing-python/) en tu computadora.

Recomendamos utilizar la biblioteca est√°ndar de Pyton [venv](https://docs.python.org/3/library/venv.html) para crear un ambiente virtual y tener Python, `pip` y todos los paquetes dependientes instalados y entregados desde el directorio del proyecto directamente para evitar problemas con cambios globales de los paquetes y sus versiones.

#### Instalar las dependencias

Instala todas las dependencias requeridas para el proyecto ejecutando:

```bash
pip install -r requirements.txt
```

#### Lanzar Jupyter Localmente

Todas las demonstraciones en este proyecto pueden ser ejecutadas directamnte en tu navegador sin necesidad de instalar Jypyter localmente. Sin embargo, si queres lanzar [Jupyter Notebook](http://jupyter.org/) localmente, es probable que lo quieras hacer utilizando el siguiente comando desde la carpeta ra√≠z del proyecto:

```bash
jupyter notebook
```
Despu√©s de esto, el Jupyter Notebook se puede accesar a trav√©s de `http://localhost:8888`.

#### Lanzar Jupyter de manera remota

Cada secci√≥n dedicada a un algoritmo contiene enlaces a [Jupyter NBViewer](http://nbviewer.jupyter.org/). Esta es una herramienta onlina muy veloz para pre-vizualisar el c√≥digo, los graficos y la data desde tu navegador sin necesidad de instalar nada localmente. En el caso que quieras _camnbiar_ el c√≥digo y _experimentar_ con el notebook, tienes que lanzarlo desde [Binder](https://mybinder.org/). Puedes hacerlo simplemente con hacer clock en _"Execute on Binder"_ en la esquina superior derecha de NBViewer.

![](./images/binder-button-place.png)

## Datasets

La lista de los datasets que son utilizados en los demos se encuentra ubicada en [data folder](data).

## Apoyo al proyecto

Puedes apoyar el proyecto v√≠a ‚ù§Ô∏èÔ∏è [GitHub](https://github.com/sponsors/trekhleb) o ‚ù§Ô∏èÔ∏è [Patreon](https://www.patreon.com/trekhleb).

## Autor

- [@trekhleb](https://trekhleb.dev)
